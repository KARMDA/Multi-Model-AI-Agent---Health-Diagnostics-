
# ğŸ§  Multi-Model AI Agent for Automated Health Diagnostics (Medicube)

A **production-grade, research-oriented multi-model AI system** for automated blood report analysis.  
The system integrates **OCR, deterministic clinical reasoning, knowledge-graphâ€“based inference, and LLM-powered narrative synthesis** into a single, auditable pipeline, exposed via a **Streamlit UI** and packaged in a **single Docker image**.

> âš ï¸ **Medical Disclaimer**  
> This platform is strictly an **assistive decision-support system** intended for educational and research use.  
> It does **not** provide diagnoses, prescriptions, or treatment recommendations.  
> All outputs must be reviewed by a qualified medical professional.

---

## âœ¨ Key Capabilities

- ğŸ“„ Accepts **PDF / Image / JSON** blood reports  
- ğŸ” OCR with robust parameter extraction  
- ğŸ§ª Parameter-level clinical interpretation (Normal / Low / High)  
- ğŸ§  Deterministic pattern detection & probabilistic risk inference  
- ğŸ§© Knowledge-graphâ€“based causal reasoning  
- âœï¸ LLM-based **explainable medical narratives** (with safety guardrails)  
- ğŸ–¥ï¸ Interactive **Streamlit UI**  
- ğŸ³ **Single unified Docker image** for reproducibility

---

## ğŸ§­ System Architecture

```
Input (PDF / Image / JSON)
        â†“
Extractor (OCR + Parsing)
        â†“
Model-1 (Clinical Parameter Normalization)
        â†“
Model-2 (Pattern, Risk & Causal Reasoning)
        â†“
Model-3 (LLM Narrative Synthesis)
        â†“
Final Report + Auditable Artifacts
```

> The system is intentionally **layered**, ensuring that:
> - Clinical facts are determined deterministically
> - Inference is explainable and traceable
> - LLMs are used only for **synthesis and communication**, not diagnosis

---

## ğŸ§© Component Breakdown

---

### 1ï¸âƒ£ Extractor â€” OCR & Structuring

**Location:** `extractor/process_file.py`

**Responsibilities**
- OCR for scanned PDFs and images  
- Text normalization and cleanup  
- Parameter detection with plausibility checks  
- Conversion into structured CSV format  

**Outputs**
```
outputs/structured_per_report/<file>.structured.csv
outputs/model1_per_report/<file>.model1_final.csv
```

---

### 2ï¸âƒ£ Modelâ€‘1 â€” Clinical Parameter Normalization

**Purpose:** Deterministic interpretation of extracted lab values

**Key Functions**
- Compares values against reference ranges  
- Assigns status labels:
  - Normal
  - Low
  - High
- Produces parameter-level notes for downstream reasoning

**Output**
```
outputs/model1_per_report/<file>.model1_final.csv
```

> Modelâ€‘1 contains **no probabilistic logic** â€” it establishes factual ground truth.

---

### 3ï¸âƒ£ Modelâ€‘2 â€” Pattern, Risk & Causal Reasoning

**Location:** `model2/`

**Design Philosophy**
- Fully **deterministic and auditable**
- No LLM dependency
- Designed to be medically traceable

**Core Concepts**
- Pattern detection (e.g., anemia, thrombocytopenia)
- Derived metrics (ratios, trends)
- Knowledge-graphâ€“based causal links
- Probabilistic priors over medical hypotheses
- Confidence scoring based on evidence completeness

**Key Files**
```
model2/
â”œâ”€â”€ model2_runner.py        # Pipeline orchestrator
â”œâ”€â”€ serializer.py           # Artifact persistence
â”œâ”€â”€ verifier.py             # Output validation
â””â”€â”€ pipeline/
    â”œâ”€â”€ loader.py
    â”œâ”€â”€ pattern_engine.py
    â”œâ”€â”€ probable_causes.py
    â”œâ”€â”€ knowledge_graph.py
    â”œâ”€â”€ risk_engine.py
    â”œâ”€â”€ confidence.py
    â”œâ”€â”€ priors.py
    â””â”€â”€ guardrails.py
```

**Outputs**
```
outputs/model2_outputs/<file>.model2.json
outputs/model2_outputs/<file>.model2.txt
```

> Modelâ€‘2 performs **reasoning**, not narration.

---

### 4ï¸âƒ£ Modelâ€‘3 â€” LLM Narrative Synthesis

**Location:** `model3/`

**Design Philosophy**
- LLM used **only for synthesis and explanation**
- No hard medical thresholds
- No diagnostic assertions
- Deterministic fallback if LLM fails

**Why no rule-based escalation here?**  
Hard thresholds and escalation logic are intentionally excluded to:
- Avoid duplicating deterministic logic already handled upstream
- Preserve LLM flexibility for context-aware explanation
- Prevent brittle rule explosion across parameters

**Key Files**
```
model3/
â”œâ”€â”€ model3_runner.py        # Orchestration
â”œâ”€â”€ prompts.py              # Prompt construction
â”œâ”€â”€ schema_model3.json      # Strict output schema
â”œâ”€â”€ guardrails.py           # Safety filters
â”œâ”€â”€ gemini_client.py        # LLM interface
â””â”€â”€ .env                    # API keys (not committed)
```

**Outputs**
```
outputs/model3/<file>.model3.json
outputs/model3/<file>.model3.txt
outputs/model3/<file>.model3.prompt.txt
```

---

## ğŸ–¥ï¸ Streamlit Application

**Entry Point:** `app.py`

**Features**
- File upload (PDF / Image / JSON)
- Patient & lifestyle context input
- Step-by-step pipeline execution
- Detailed Modelâ€‘2 reasoning visualization
- Structured Modelâ€‘3 narrative output
- Artifact downloads
- Debug & audit views

Run locally:
```bash
streamlit run app.py
```

---

## ğŸ³ Docker Setup (Single Image)

This project intentionally uses **one unified Docker image** for:
- Reproducibility
- Simplicity
- Academic & research deployment

**Key Files**
```
Dockerfile.ui
requirements.ui.txt
```

**Build**
```bash
docker build -f Dockerfile.ui -t medicube-ai .
```

**Run**
```bash
docker run -p 8501:8501 medicube-ai
```

Open:
```
http://localhost:8501
```

---

## ğŸ“ Full Project Structure

```
.
â”œâ”€â”€ app.py
â”œâ”€â”€ Dockerfile.ui
â”œâ”€â”€ requirements.ui.txt
â”œâ”€â”€ extractor/
â”‚   â””â”€â”€ process_file.py
â”œâ”€â”€ model2/
â”‚   â”œâ”€â”€ model2_runner.py
â”‚   â”œâ”€â”€ serializer.py
â”‚   â”œâ”€â”€ verifier.py
â”‚   â””â”€â”€ pipeline/
â”œâ”€â”€ model3/
â”‚   â”œâ”€â”€ model3_runner.py
â”‚   â”œâ”€â”€ prompts.py
â”‚   â”œâ”€â”€ schema_model3.json
â”‚   â”œâ”€â”€ guardrails.py
â”‚   â””â”€â”€ gemini_client.py
â”œâ”€â”€ samples/
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ architecture_flow.png
â””â”€â”€ outputs/        # ignored in git
```

---

## ğŸ” Safety & Guardrails

- No prescriptions or dosages generated
- Conservative language enforced
- Strict JSON schema validation
- Deterministic fallback when LLM fails
- Full audit trail (inputs, prompts, outputs)

---

## ğŸš€ Project Status

âœ” End-to-end pipeline complete  
âœ” Deterministic reasoning core stable  
âœ” LLM integration guarded & auditable  
âœ” Streamlit UI functional  
âœ” Dockerized & reproducible  

---

## ğŸ“„ License

For academic, educational, and research use only.
